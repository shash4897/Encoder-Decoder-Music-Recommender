{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRS_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNWQSmZc_w_7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d83f1c23-a174-4be1-d2cb-286a02f1f7c5"
      },
      "source": [
        "!pip install dummyPy\n",
        "#!git clone https://github.com/neonbjb/ml-notebooks.git\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dummyPy in /usr/local/lib/python3.6/dist-packages (0.3)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGzFjkGfHRMU"
      },
      "source": [
        "import os\n",
        "import csv\n",
        "from math import ceil\n",
        "import pandas as pd\n",
        "import string\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, LSTMCell\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.utils import Sequence\n",
        "from keras.utils import plot_model\n",
        "from dummyPy import OneHotEncoder\n",
        "from scipy import spatial\n",
        "from sys import setrecursionlimit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFyXqRzwHpFJ"
      },
      "source": [
        "basedir = \"MRS/\"\n",
        "#songlistdf = pd.read_csv(os.path.join(basedir,'spotify_songs.csv'))\n",
        "playlistdf = pd.read_csv(os.path.join(basedir,'Dataset/spotify_data.csv'))\n",
        "\n",
        "NUM_SAMPLES = 1000\n",
        "train_samples = 600\n",
        "val_samples = 200\n",
        "test_samples = 200\n",
        "\n",
        "#vocab_len = len(songlistdf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwUpJSGpAa5u"
      },
      "source": [
        "max_seq_len = 0\n",
        "playlistdf['pid'].apply(int)\n",
        "\n",
        "for name,group in playlistdf.groupby('pid'):\n",
        "  max_seq_len = max(max_seq_len,len(group))\n",
        "\n",
        "onehotencoder = OneHotEncoder([\"time_signature\", \"key\", \"mode\"])\n",
        "onehotencoder.fit(playlistdf)\n",
        "proc_playlistdf=onehotencoder.transform(playlistdf)\n",
        "cols_to_norm = ['duration_ms','loudness','tempo']\n",
        "proc_playlistdf[cols_to_norm] = proc_playlistdf[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0l8pHcHLEzu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "b3d043a6-dd01-4c19-c175-3255338438a3"
      },
      "source": [
        "print(max_seq_len)\n",
        "print(proc_playlistdf.shape)\n",
        "print(proc_playlistdf.columns.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "245\n",
            "(67500, 37)\n",
            "['acousticness' 'analysis_url' 'artist_name' 'danceability' 'duration_ms'\n",
            " 'energy' 'id' 'instrumentalness' 'key_0' 'key_1' 'key_2' 'key_3' 'key_4'\n",
            " 'key_5' 'key_6' 'key_7' 'key_8' 'key_9' 'key_10' 'key_11' 'liveness'\n",
            " 'loudness' 'mode_0' 'mode_1' 'pid' 'speechiness' 'tempo'\n",
            " 'time_signature_0' 'time_signature_1' 'time_signature_3'\n",
            " 'time_signature_4' 'time_signature_5' 'track_href' 'track_name' 'type'\n",
            " 'uri' 'valence']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7MdosRLMgjk"
      },
      "source": [
        "reg_features = ['acousticness','danceability','duration_ms','energy','instrumentalness','liveness','loudness','speechiness','tempo','valence']\n",
        "key_features = ['key_0','key_1','key_2','key_3','key_4','key_5','key_6','key_7','key_8','key_9','key_10','key_11']\n",
        "mode_features = ['mode_0','mode_1']\n",
        "timesig_features= ['time_signature_0', 'time_signature_1', 'time_signature_3', 'time_signature_4', 'time_signature_5']\n",
        "\n",
        "def get_data_arrays(groupbyuser):\n",
        "  \n",
        "  enc_input_data = []\n",
        "  dec_input_data = []\n",
        "  dec_target_reg = []\n",
        "  dec_target_key = []\n",
        "  dec_target_mode = []\n",
        "  dec_target_timesig = []\n",
        "\n",
        "  for name,group in groupbyuser:\n",
        "      grp = group.drop(['analysis_url','artist_name','id','track_href','track_name','type','uri','pid'],axis=1)\n",
        "      \n",
        "      grouplist = grp.values\n",
        "      grouplist_reg = grp[reg_features].values\n",
        "      grouplist_key = grp[key_features].values\n",
        "      grouplist_mode = grp[mode_features].values\n",
        "      grouplist_timesig = grp[timesig_features].values\n",
        "      \n",
        "      xgroup = grouplist[0:len(grouplist)-1]\n",
        "      ygroup = grouplist[1:len(grouplist)]\n",
        "      ytarget_reg = grouplist_reg[2:len(grouplist_reg)]\n",
        "      ytarget_key = grouplist_key[2:len(grouplist_key)]\n",
        "      ytarget_mode = grouplist_mode[2:len(grouplist_mode)]\n",
        "      ytarget_timesig = grouplist_timesig[2:len(grouplist_timesig)]\n",
        "      \n",
        "      for i in range((max_seq_len-len(xgroup))):\n",
        "          xgroup=np.vstack([xgroup,np.zeros(xgroup.shape[1])])\n",
        "\n",
        "      for i in range((max_seq_len-len(ygroup))):\n",
        "          ygroup=np.vstack([ygroup,np.zeros(ygroup.shape[1])])\n",
        "\n",
        "      for i in range((max_seq_len-len(ytarget_reg))):\n",
        "          ytarget_reg=np.vstack([ytarget_reg,np.zeros(ytarget_reg.shape[1])])\n",
        "      \n",
        "      for i in range((max_seq_len-len(ytarget_key))):\n",
        "          ytarget_key=np.vstack([ytarget_key,np.zeros(ytarget_key.shape[1])])\n",
        "      \n",
        "      for i in range((max_seq_len-len(ytarget_mode))):\n",
        "          ytarget_mode=np.vstack([ytarget_mode,np.zeros(ytarget_mode.shape[1])])\n",
        "      \n",
        "      for i in range((max_seq_len-len(ytarget_timesig))):\n",
        "          ytarget_timesig=np.vstack([ytarget_timesig,np.zeros(ytarget_timesig.shape[1])])\n",
        "\n",
        "      enc_input_data.append(xgroup)\n",
        "      dec_input_data.append(ygroup)\n",
        "      dec_target_reg.append(ytarget_reg)\n",
        "      dec_target_key.append(ytarget_key)\n",
        "      dec_target_mode.append(ytarget_mode)\n",
        "      dec_target_timesig.append(ytarget_timesig)\n",
        "\n",
        "  enc_input_data= np.array(enc_input_data)\n",
        "  dec_input_data = np.array(dec_input_data)\n",
        "  dec_target_reg = np.array(dec_target_reg)\n",
        "  dec_target_key = np.array(dec_target_key)\n",
        "  dec_target_mode = np.array(dec_target_mode)\n",
        "  dec_target_timesig = np.array(dec_target_timesig)\n",
        "  \n",
        "  return enc_input_data,dec_input_data,dec_target_reg,dec_target_key,dec_target_mode,dec_target_timesig\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieD8lgrzWKhm"
      },
      "source": [
        "groupbyuser = proc_playlistdf.groupby('pid')\n",
        "enc_input,dec_input,dec_target_reg,dec_target_key,dec_target_mode,dec_target_timesig= get_data_arrays(groupbyuser)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yLYl1bQoZ1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "e9797dc7-57e1-4ab3-d9d6-86a01936a4cf"
      },
      "source": [
        "enc_input_train,dec_input_train,dec_target_reg_train,dec_target_key_train,dec_target_mode_train,dec_target_timesig_train = enc_input[:train_samples],dec_input[:train_samples],dec_target_reg[:train_samples],dec_target_key[:train_samples],dec_target_mode[:train_samples],dec_target_timesig[:train_samples]\n",
        "\n",
        "enc_input_val,dec_input_val,dec_target_reg_val,dec_target_key_val,dec_target_mode_val,dec_target_timesig_val = enc_input[train_samples:train_samples + val_samples],dec_input[train_samples:train_samples+val_samples],dec_target_reg[train_samples:train_samples+val_samples],dec_target_key[train_samples:train_samples+val_samples],dec_target_mode[train_samples:train_samples+val_samples],dec_target_timesig[train_samples:train_samples+val_samples]\n",
        "\n",
        "enc_input_test,dec_input_test,dec_target_reg_test,dec_target_key_test,dec_target_mode_test,dec_target_timesig_test = enc_input[train_samples + val_samples:train_samples + val_samples + test_samples],dec_input[train_samples + val_samples:train_samples + val_samples + test_samples],dec_target_reg[train_samples + val_samples:train_samples + val_samples + test_samples],dec_target_key[train_samples + val_samples:train_samples + val_samples + test_samples],dec_target_mode[train_samples + val_samples:train_samples + val_samples + test_samples],dec_target_timesig[train_samples + val_samples:train_samples + val_samples + test_samples]\n",
        "\n",
        "print(enc_input_train.shape)\n",
        "print(dec_input_train.shape)\n",
        "print(dec_target_reg_train.shape)\n",
        "print(dec_target_key_train.shape)\n",
        "print(dec_target_mode_train.shape)\n",
        "print(dec_target_timesig_train.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(600, 245, 29)\n",
            "(600, 245, 29)\n",
            "(600, 245, 10)\n",
            "(600, 245, 12)\n",
            "(600, 245, 2)\n",
            "(600, 245, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O9CR_aTdir_"
      },
      "source": [
        "setrecursionlimit(10000)\n",
        "\n",
        "song_vocab = proc_playlistdf.drop(['analysis_url','artist_name','track_href','type','uri','pid'],axis=1).drop_duplicates('id')\n",
        "\n",
        "song_vocab_vecs = song_vocab.drop(['id','track_name'],axis=1).values\n",
        "\n",
        "sim_tree = spatial.KDTree(song_vocab_vecs)\n",
        "\n",
        "proc_playlistdf.to_csv(os.path.join(basedir,\"Dataset/norm_playlists.csv\"),index=False)\n",
        "song_vocab.to_csv(os.path.join(basedir,\"Dataset/norm_songs.csv\"),index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY48dbsbxrNL"
      },
      "source": [
        "# Generator function to generate \n",
        "class my_generator(Sequence):\n",
        "\n",
        "    def __init__(self, enc_inp,dec_inp,dec_tar_reg,dec_tar_key,dec_tar_mode,dec_tar_timesig,batch_size):\n",
        "        self.enc_inp = enc_inp\n",
        "        self.dec_inp = dec_inp\n",
        "        self.dec_tar_reg = dec_tar_reg\n",
        "        self.dec_tar_key = dec_tar_key\n",
        "        self.dec_tar_mode = dec_tar_mode\n",
        "        self.dec_tar_timesig = dec_tar_timesig\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return ceil(self.enc_inp.shape[0] / float(self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc_inp_batch = self.enc_inp[idx*batch_size:(idx+1)*batch_size]\n",
        "        dec_inp_batch = self.dec_inp[idx*batch_size:(idx+1)*batch_size]\n",
        "        dec_tar_reg_batch = self.dec_tar_reg[idx*batch_size:(idx+1)*batch_size]\n",
        "        dec_tar_key_batch = self.dec_tar_key[idx*batch_size:(idx+1)*batch_size]\n",
        "        dec_tar_mode_batch = self.dec_tar_mode[idx*batch_size:(idx+1)*batch_size]\n",
        "        dec_tar_timesig_batch = self.dec_tar_timesig[idx*batch_size:(idx+1)*batch_size]\n",
        "        \n",
        "        return [enc_inp_batch,dec_inp_batch],[dec_tar_reg_batch,dec_tar_key_batch,dec_tar_mode_batch,dec_tar_timesig_batch]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSNkPxRQWPGe"
      },
      "source": [
        "# training model\n",
        "latent_dim = 256\n",
        "\n",
        "encoder_inputs = Input(shape=(None, enc_input.shape[2]))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, dec_input.shape[2]))\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
        "  \n",
        "reg_layer = Dense(dec_target_reg.shape[2],activation = 'sigmoid', name = 'reg_output')\n",
        "key_layer = Dense(dec_target_key.shape[2],activation = 'softmax', name = 'key_output')\n",
        "mode_layer = Dense(dec_target_mode.shape[2],activation = 'softmax', name = 'mode_output')\n",
        "timesig_layer = Dense(dec_target_timesig.shape[2],activation = 'softmax', name = 'timesig_output')\n",
        "  \n",
        "decoder_outputs_reg = reg_layer(decoder_outputs)\n",
        "decoder_outputs_key = key_layer(decoder_outputs)\n",
        "decoder_outputs_mode = mode_layer(decoder_outputs)\n",
        "decoder_outputs_timesig = timesig_layer(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], [decoder_outputs_reg,decoder_outputs_key,decoder_outputs_mode,decoder_outputs_timesig])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQS578RNWlDv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "outputId": "12982c14-0882-4095-ea98-cf721039a546"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 20 \n",
        "\n",
        "train_gen = my_generator(enc_input_train,dec_input_train,dec_target_reg_train,dec_target_key_train,dec_target_mode_train,dec_target_timesig_train,batch_size)\n",
        "val_gen = my_generator(enc_input_val,dec_input_val,dec_target_reg_val,dec_target_key_val,dec_target_mode_val,dec_target_timesig_val,batch_size)\n",
        "\n",
        "loss_funcs = {\n",
        "    'reg_output':'mse',\n",
        "    'key_output':'categorical_crossentropy',\n",
        "    'mode_output':'categorical_crossentropy',\n",
        "    'timesig_output':'categorical_crossentropy'\n",
        "}\n",
        "\n",
        "loss_wts = {\n",
        "    'reg_output': 1.0,\n",
        "    'key_output': 1.0,\n",
        "    'mode_output': 1.0,\n",
        "    'timesig_output': 1.0\n",
        "}\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss=loss_funcs,loss_weights=loss_wts )\n",
        "\n",
        "model.fit_generator(generator=train_gen,\n",
        "                    validation_data=val_gen,\n",
        "                    use_multiprocessing=True,\n",
        "                    workers=4,\n",
        "                    epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "18/19 [===========================>..] - ETA: 0s - loss: 1.0524 - reg_output_loss: 0.1029 - key_output_loss: 0.6504 - mode_output_loss: 0.1849 - timesig_output_loss: 0.1141Epoch 1/20\n",
            "Epoch 1/20\n",
            "19/19 [==============================] - 19s 990ms/step - loss: 1.0379 - reg_output_loss: 0.0990 - key_output_loss: 0.6447 - mode_output_loss: 0.1828 - timesig_output_loss: 0.1114 - val_loss: 0.9230 - val_reg_output_loss: 0.0294 - val_key_output_loss: 0.6465 - val_mode_output_loss: 0.1687 - val_timesig_output_loss: 0.0785\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 15s 780ms/step - loss: 0.9167 - reg_output_loss: 0.0213 - key_output_loss: 0.6415 - mode_output_loss: 0.1715 - timesig_output_loss: 0.0824 - val_loss: 0.9045 - val_reg_output_loss: 0.0125 - val_key_output_loss: 0.6454 - val_mode_output_loss: 0.1699 - val_timesig_output_loss: 0.0768\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 15s 796ms/step - loss: 0.9098 - reg_output_loss: 0.0198 - key_output_loss: 0.6404 - mode_output_loss: 0.1685 - timesig_output_loss: 0.0811 - val_loss: 0.8989 - val_reg_output_loss: 0.0116 - val_key_output_loss: 0.6449 - val_mode_output_loss: 0.1670 - val_timesig_output_loss: 0.0755\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 17s 870ms/step - loss: 0.8989 - reg_output_loss: 0.0112 - key_output_loss: 0.6405 - mode_output_loss: 0.1675 - timesig_output_loss: 0.0797 - val_loss: 0.9014 - val_reg_output_loss: 0.0107 - val_key_output_loss: 0.6445 - val_mode_output_loss: 0.1714 - val_timesig_output_loss: 0.0749\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 15s 785ms/step - loss: 0.8989 - reg_output_loss: 0.0107 - key_output_loss: 0.6394 - mode_output_loss: 0.1678 - timesig_output_loss: 0.0811 - val_loss: 0.8970 - val_reg_output_loss: 0.0114 - val_key_output_loss: 0.6436 - val_mode_output_loss: 0.1675 - val_timesig_output_loss: 0.0745\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 15s 788ms/step - loss: 0.8925 - reg_output_loss: 0.0102 - key_output_loss: 0.6383 - mode_output_loss: 0.1654 - timesig_output_loss: 0.0787 - val_loss: 0.8919 - val_reg_output_loss: 0.0096 - val_key_output_loss: 0.6420 - val_mode_output_loss: 0.1661 - val_timesig_output_loss: 0.0743\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 15s 784ms/step - loss: 0.8902 - reg_output_loss: 0.0094 - key_output_loss: 0.6380 - mode_output_loss: 0.1651 - timesig_output_loss: 0.0778 - val_loss: 0.8907 - val_reg_output_loss: 0.0090 - val_key_output_loss: 0.6423 - val_mode_output_loss: 0.1657 - val_timesig_output_loss: 0.0737\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 15s 803ms/step - loss: 0.8907 - reg_output_loss: 0.0093 - key_output_loss: 0.6385 - mode_output_loss: 0.1646 - timesig_output_loss: 0.0783 - val_loss: 0.8891 - val_reg_output_loss: 0.0088 - val_key_output_loss: 0.6425 - val_mode_output_loss: 0.1646 - val_timesig_output_loss: 0.0732\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 16s 856ms/step - loss: 0.8868 - reg_output_loss: 0.0088 - key_output_loss: 0.6375 - mode_output_loss: 0.1639 - timesig_output_loss: 0.0767 - val_loss: 0.8907 - val_reg_output_loss: 0.0087 - val_key_output_loss: 0.6431 - val_mode_output_loss: 0.1660 - val_timesig_output_loss: 0.0729\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 15s 776ms/step - loss: 0.8918 - reg_output_loss: 0.0111 - key_output_loss: 0.6374 - mode_output_loss: 0.1640 - timesig_output_loss: 0.0793 - val_loss: 0.8869 - val_reg_output_loss: 0.0085 - val_key_output_loss: 0.6408 - val_mode_output_loss: 0.1643 - val_timesig_output_loss: 0.0734\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 15s 781ms/step - loss: 0.8841 - reg_output_loss: 0.0084 - key_output_loss: 0.6371 - mode_output_loss: 0.1628 - timesig_output_loss: 0.0758 - val_loss: 0.8859 - val_reg_output_loss: 0.0082 - val_key_output_loss: 0.6412 - val_mode_output_loss: 0.1638 - val_timesig_output_loss: 0.0727\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 15s 782ms/step - loss: 0.8838 - reg_output_loss: 0.0084 - key_output_loss: 0.6365 - mode_output_loss: 0.1630 - timesig_output_loss: 0.0760 - val_loss: 0.8900 - val_reg_output_loss: 0.0081 - val_key_output_loss: 0.6426 - val_mode_output_loss: 0.1664 - val_timesig_output_loss: 0.0729\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 15s 783ms/step - loss: 0.8837 - reg_output_loss: 0.0082 - key_output_loss: 0.6360 - mode_output_loss: 0.1637 - timesig_output_loss: 0.0758 - val_loss: 0.8858 - val_reg_output_loss: 0.0082 - val_key_output_loss: 0.6406 - val_mode_output_loss: 0.1640 - val_timesig_output_loss: 0.0730\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 17s 869ms/step - loss: 0.8828 - reg_output_loss: 0.0081 - key_output_loss: 0.6361 - mode_output_loss: 0.1616 - timesig_output_loss: 0.0769 - val_loss: 0.8862 - val_reg_output_loss: 0.0082 - val_key_output_loss: 0.6412 - val_mode_output_loss: 0.1634 - val_timesig_output_loss: 0.0734\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 15s 788ms/step - loss: 0.8822 - reg_output_loss: 0.0079 - key_output_loss: 0.6361 - mode_output_loss: 0.1625 - timesig_output_loss: 0.0757 - val_loss: 0.8834 - val_reg_output_loss: 0.0079 - val_key_output_loss: 0.6399 - val_mode_output_loss: 0.1628 - val_timesig_output_loss: 0.0729\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 15s 785ms/step - loss: 0.8814 - reg_output_loss: 0.0078 - key_output_loss: 0.6359 - mode_output_loss: 0.1622 - timesig_output_loss: 0.0755 - val_loss: 0.8868 - val_reg_output_loss: 0.0077 - val_key_output_loss: 0.6420 - val_mode_output_loss: 0.1646 - val_timesig_output_loss: 0.0725\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 15s 795ms/step - loss: 0.8802 - reg_output_loss: 0.0077 - key_output_loss: 0.6354 - mode_output_loss: 0.1619 - timesig_output_loss: 0.0753 - val_loss: 0.8843 - val_reg_output_loss: 0.0077 - val_key_output_loss: 0.6410 - val_mode_output_loss: 0.1628 - val_timesig_output_loss: 0.0727\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 15s 788ms/step - loss: 0.8814 - reg_output_loss: 0.0085 - key_output_loss: 0.6358 - mode_output_loss: 0.1614 - timesig_output_loss: 0.0757 - val_loss: 0.8856 - val_reg_output_loss: 0.0078 - val_key_output_loss: 0.6402 - val_mode_output_loss: 0.1651 - val_timesig_output_loss: 0.0726\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 16s 833ms/step - loss: 0.8793 - reg_output_loss: 0.0075 - key_output_loss: 0.6348 - mode_output_loss: 0.1619 - timesig_output_loss: 0.0751 - val_loss: 0.8850 - val_reg_output_loss: 0.0077 - val_key_output_loss: 0.6410 - val_mode_output_loss: 0.1636 - val_timesig_output_loss: 0.0727\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 15s 796ms/step - loss: 0.8796 - reg_output_loss: 0.0075 - key_output_loss: 0.6352 - mode_output_loss: 0.1621 - timesig_output_loss: 0.0748 - val_loss: 0.8881 - val_reg_output_loss: 0.0075 - val_key_output_loss: 0.6428 - val_mode_output_loss: 0.1656 - val_timesig_output_loss: 0.0723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3789ce0198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpDv4Chd5wdv"
      },
      "source": [
        "#inferencing model\n",
        "\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_outputs_reg = reg_layer(decoder_outputs)\n",
        "decoder_outputs_key = key_layer(decoder_outputs)\n",
        "decoder_outputs_mode = mode_layer(decoder_outputs)\n",
        "decoder_outputs_timesig = timesig_layer(decoder_outputs)\n",
        "\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs,[decoder_outputs_reg,decoder_outputs_key,decoder_outputs_mode,decoder_outputs_timesig] + decoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XucQXUxFXkiV"
      },
      "source": [
        "def prep_sos_seq(input_seq):\n",
        "\n",
        "    inp_seq = input_seq[0]\n",
        "    reg_idx = [0,1,2,3,4,17,18,21,22,28]\n",
        "    key_idx = [5,6,7,8,9,10,11,12,13,14,15,16]\n",
        "    mode_idx = [19,20]\n",
        "    time_sig_idx = [23,24,25,26,27]\n",
        "\n",
        "    inp_seq_reg = np.mean(np.take(inp_seq,reg_idx,axis=1),axis=0)\n",
        "\n",
        "    inp_seq_key = np.zeros(12)\n",
        "    inp_seq_key[np.argmax(np.sum(np.take(inp_seq,key_idx,axis=1),axis=0))] = 1\n",
        "\n",
        "    inp_seq_mode = np.zeros(2)\n",
        "    inp_seq_key[np.argmax(np.sum(np.take(inp_seq,mode_idx,axis=1),axis=0))] = 1\n",
        "\n",
        "    inp_seq_timesig = np.zeros(5)\n",
        "    inp_seq_timesig[np.argmax(np.sum(np.take(inp_seq,time_sig_idx,axis=1),axis=0))] = 1\n",
        "\n",
        "    sos_vec = np.concatenate((inp_seq_reg[0:5],inp_seq_key))\n",
        "    sos_vec = np.concatenate((sos_vec,inp_seq_reg[5:7]))\n",
        "    sos_vec = np.concatenate((sos_vec,inp_seq_mode))\n",
        "    sos_vec = np.concatenate((sos_vec,inp_seq_reg[7:9]))\n",
        "    sos_vec = np.concatenate((sos_vec,inp_seq_timesig))\n",
        "    sos_vec = np.append(sos_vec,inp_seq_reg[9])\n",
        "\n",
        "    sos_vec = sos_vec.reshape((1,1,-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjz1RfmW9jEZ"
      },
      "source": [
        "max_playlist_len = 5\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    \n",
        "    sos_vec = prep_sos_seq(input_seq)\n",
        "    \n",
        "    eos_vec = np.zeros(29)\n",
        "    \n",
        "    target_seq = sos_vec\n",
        "    \n",
        "    stop_condition = False\n",
        "    rec_song_ids = []\n",
        "    \n",
        "    while not stop_condition:\n",
        "      \n",
        "        reg, key, mode, timesig ,h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Process outputs to produce input for next time step\n",
        "        songid,song_vec = getclosestsong(reg[0,-1,:],key[0,-1,:],mode[0,-1,:],timesig[0,-1,:])\n",
        "        rec_song_ids.append(songid)\n",
        "      \n",
        "        # Exit condition:  hit max sequence length\n",
        "        if (len(rec_song_ids) > max_playlist_len):\n",
        "            stop_condition = True\n",
        "        \n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = song_vec\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return rec_song_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCa1seKzXP2K"
      },
      "source": [
        "def getclosestsong(reg,key,mode,timesig):\n",
        "  feat_vec_pred = {\n",
        "      'acousticness':reg[0],\n",
        "      'danceability':reg[1],\n",
        "      'duration_ms':reg[2],\n",
        "      'energy':reg[3],\n",
        "      'instrumentalness':reg[4],\n",
        "      'key_0':key[0],\n",
        "      'key_1':key[1],\n",
        "      'key_2':key[2],\n",
        "      'key_3':key[3],\n",
        "      'key_4':key[4],\n",
        "      'key_5':key[5],\n",
        "      'key_6':key[6],\n",
        "      'key_7':key[7],\n",
        "      'key_8':key[8],\n",
        "      'key_9':key[9],\n",
        "      'key_10':key[10],\n",
        "      'key_11':key[11],\n",
        "      'liveness':reg[5],\n",
        "      'loudness':reg[6],\n",
        "      'mode_0':mode[0],\n",
        "      'mode_1':mode[1],\n",
        "      'speechiness':reg[7],\n",
        "      'tempo':reg[8],\n",
        "      'time_signature_0':timesig[0],\n",
        "      'time_signature_1':timesig[1],\n",
        "      'time_signature_3':timesig[2],\n",
        "      'time_signature_4':timesig[3],\n",
        "      'time_signature_5':timesig[4],\n",
        "      'valence':reg[9]\n",
        "  }\n",
        "  \n",
        "  feat_vec_pred = np.array(list(feat_vec_pred.values()))\n",
        "  \n",
        "  _ , idx = sim_tree.query(feat_vec_pred)\n",
        "  \n",
        "  songid =  song_vocab.iloc[idx]['id']\n",
        "  \n",
        "  songvec = song_vocab_vecs[idx].reshape((1,1,-1))\n",
        "  \n",
        "  return songid,songvec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeuPisqE7a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "8937f153-2df5-496c-cd95-8ca5c8b09202"
      },
      "source": [
        "ipseqtest = np.array([enc_input_test[16]])\n",
        "\n",
        "recommendation_ids = decode_sequence(ipseqtest)\n",
        "\n",
        "print(recommendation_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-b216350e6220>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mipseqtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menc_input_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrecommendation_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mipseqtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommendation_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-b650e639304d>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         reg, key, mode, timesig ,h, c = decoder_model.predict(\n\u001b[0;32m---> 19\u001b[0;31m             [target_seq] + states_value)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Process outputs to produce input for next time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hzMXCOvKOSP"
      },
      "source": [
        "model.save(os.path.join(basedir,\"Model/train_model.h5\"))\n",
        "encoder_model.save(os.path.join(basedir,\"Model/inf_encoder.h5\"))\n",
        "decoder_model.save(os.path.join(basedir,\"Model/inf_decoder.h5\"))\n",
        "\n",
        "plot_model(model,to_file = os.path.join(basedir,'Model/model.png'))\n",
        "plot_model(encoder_model,to_file = os.path.join(basedir,'Model/encoder.png'))\n",
        "plot_model(decoder_model,to_file = os.path.join(basedir,'Model/decoder.png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAnyxeBnwZ8z"
      },
      "source": [
        "np.take([[13,4,1],[2,5,6],[7,0,11]],[0,1],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}